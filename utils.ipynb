{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='6px'> Utils </font> \n",
    "<br>\n",
    "<ol>\n",
    "    <li> Read Tappy file and user file</li>\n",
    "    <li> Batch Generator </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import Sequence\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readXY(x_path,y_path):\n",
    "    \n",
    "    # read all the files (i.e 8490) in form as array\n",
    "    X = os.listdir(x_path)\n",
    "    \n",
    "    # read excel file as a dataframe\n",
    "    df_excel = pd.read_excel(y_path)\n",
    "    \n",
    "    # convert dataframe to numpy matrix\n",
    "    Y = df_excel.as_matrix()\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xProcess(_X,gender):\n",
    "    \n",
    "    X = []\n",
    "    \n",
    "    # datetime.time object\n",
    "    ptime = _X[0][2]\n",
    "    for row in _X:\n",
    "        \n",
    "        if type(row[2])==type(ptime):\n",
    "            time1 = row[2].hour*60*60 + row[2].minute*60 + row[2].second + row[2].microsecond/1000000\n",
    "            time2 = ptime.hour*60*60 + ptime.minute*60 + ptime.second + ptime.microsecond/1000000\n",
    "            dtime = time1 - time2\n",
    "            ptime = row[2]\n",
    "        else:\n",
    "            print(\"\\n number detected row: \\n\",row)\n",
    "        \n",
    "        #temp= [dtime, gender, row[3], row[4], row[5],row[6:9],row[9:] ]\n",
    "        #print(\"row[0] :\",type(row[0]))\n",
    "        #print(\"row[1] :\",type(row[1]))\n",
    "        #print(\"row[2] :\",type(row[2]))\n",
    "        #print(\"row[3] :\",type(row[3]))\n",
    "        #print(\"row[4] :\",type(row[4]))\n",
    "        #print(\"row[5] :\",type(row[5]))\n",
    "        #print(\"row[6] :\",type(row[6]))\n",
    "        #print(\"row[7] :\",type(row[7]))\n",
    "        #print(\"row[8] :\",type(row[8]))\n",
    "        #print(\"row[9] :\",type(row[9]))\n",
    "        #print(\"row[10] :\",type(row[10]))\n",
    "        #print(\"row[11] :\",type(row[11]))\n",
    "        #print(\"row[12] :\",type(row[12]))\n",
    "        #print(\"row[13] :\",type(row[13]))\n",
    "        \n",
    "        # Considering dtime that is time interval between register of two keystrokes\n",
    "        # but values seems redundant because we already have  -> Hold_time,Latency_time,Flight_time\n",
    "        # temp= np.asarray([dtime,gender])\n",
    "        \n",
    "        # gender\n",
    "        temp= np.asarray([])\n",
    "        temp = np.concatenate((temp,row[3:]), axis=0)\n",
    "\n",
    "        X.append(temp)\n",
    "        \n",
    "    \n",
    "    return X\n",
    "        \n",
    "\n",
    "def TextProcess(X_arr,Y_dict,x_path):\n",
    "    \n",
    "    leng = len(X_arr)\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for index in range(leng):\n",
    "        \n",
    "        # read excel file as a dataframe\n",
    "        df_excel = pd.read_excel(x_path+X_arr[index])\n",
    "        \n",
    "        df_excel = df_excel.dropna(axis=0, how='any')\n",
    "        \n",
    "        # normalize selected colum  Hold_time,Latency_time,Flight_time\n",
    "        cols_to_norm = ['Hold_time','Latency_time','Flight_time']\n",
    "        #df_excel[cols_to_norm] = df_excel[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "        df_excel[cols_to_norm] = df_excel[cols_to_norm].apply(lambda x: (x - x.mean()) / x.std())\n",
    "        \n",
    "        \n",
    "        #print(df_excel)\n",
    "        # convert dataframe to numpy matrix\n",
    "        x_individual = df_excel.as_matrix()\n",
    "        \n",
    "        \n",
    "        # using userid to detect is Y_dict['userId']\n",
    "        # some case might have userid field error or we might not have userid data\n",
    "        # hence skip them\n",
    "        user_id = X_arr[index].split('_')[0]\n",
    "        #print(user_id)\n",
    "        if user_id not in Y_dict.keys(): \n",
    "            print(x_path+\"/\"+X_arr[index],x_individual[0][0])\n",
    "        \n",
    "        y_app = Y_dict[user_id]\n",
    "\n",
    "        #print(x_individual[0])\n",
    "\n",
    "        \n",
    "        x_individual = xProcess(x_individual,y_app[2])\n",
    "        \n",
    "        #print(x_individual)\n",
    "        \n",
    "        X.append(np.asarray(x_individual))\n",
    "\n",
    "        # 3 index -> Parkinsons\n",
    "        y_value = y_app[3]\n",
    "        Y.append([ 1 - y_value, y_value])\n",
    "        \n",
    "        #break\n",
    "        \n",
    "        \n",
    "    #print(X)\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y,dtype=np.float32)\n",
    "    return X,Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence is from keras\n",
    "class CustomBatchGenerator(Sequence):\n",
    "    \n",
    "    # X : array([\"user_YYMMDD.txt\",.........])\n",
    "    # \n",
    "    # Y will be array of : array([user,BirthYear,Gender,Parkinsons,Tremors,DiagnosisYear,Levadopa,DA,MAOB,Other,\n",
    "    #                           Impact_Medium,Impact_Mild,Impact_Severe,Sided_Left,Sided_None,Sided_Right,\n",
    "    #                           UPDRS_1.0,UPDRS_2.0,UPDRS_3.0,UPDRS_4.0])\n",
    "    def __init__(self, X,Y, x_path, BATCH_SIZE,display_in=1):\n",
    "        \n",
    "        self.BatchS = BATCH_SIZE\n",
    "        self.display_in = display_in\n",
    "        self.batch_number = 0\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "        self.x_path = x_path\n",
    "        \n",
    "        self.Y_dict = {}\n",
    "        for row in self.Y:\n",
    "            self.Y_dict[row[0]]= row\n",
    "    \n",
    "    \n",
    "    # Inhertied from keras.utils.Sequence\n",
    "    # __len__ function returns number of steps to be taken to complete one epoch\n",
    "    def __len__(self):\n",
    "        return int(float(len(self.X)/self.BatchS))\n",
    "\n",
    "    # Inhertied from keras.utils.Sequence\n",
    "    # This function extecutes after each epoch\n",
    "    def on_epoch_end(self):\n",
    "        print(\"epoch Ended: \",self.batch_number)\n",
    "        self.batch_number = 0\n",
    "        np.random.shuffle(self.X)\n",
    "\n",
    "    # Inhertied from keras.utils.Sequence\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        #\n",
    "        #   __len__ function returns number of steps to be taken to complete one epoch\n",
    "        #   and idx represents each step\n",
    "        #   \n",
    "        #   l_bound and r_bound are to get the certain number of data in form of batches from entire dataset \n",
    "        #   given the step count for total number of iterations/ epochs \n",
    "        #\n",
    "        #if self.batch_number%self.display_in==0:\n",
    "        #    print(\" Batch: \", self.batch_number)\n",
    "        self.batch_number = self.batch_number + 1\n",
    "\n",
    "        l_bound = idx * self.BatchS\n",
    "        r_bound = (idx+1) * self.BatchS\n",
    "\n",
    "        X,Y = TextProcess(self.X[l_bound:r_bound],self.Y_dict,self.x_path)\n",
    "        \n",
    "        #print(X.shape)\n",
    "        \n",
    "        # output: X,Y\n",
    "        # All details used for X can be provided users while time of testing for parkisons\n",
    "        # X will be a array of : array([Gender,Hold_time,Latency_time,Flight_time,\n",
    "        #                              oneHot[Hand_Kpressed_L,Hand_Kpressed_R,Hand_Kpressed_S],\n",
    "        #                              oneHot[Direction_LL,Direction_LR,Direction_LS,Direction_RL,\n",
    "        #                              Direction_RR,Direction_RS,Direction_SL,Direction_SR, Direction_SS]])\n",
    "        #\n",
    "        # Y : array([Parkinsons,......])\n",
    "        return X, Y\n",
    "\n",
    "#x_path = \"F:/parkisons/code/processed_dataset/furtherProcessed_tappy_data/\"\n",
    "#y_path = \"F:/parkisons/code/processed_dataset/User_details.xlsx\"\n",
    "#X, Y = readXY(x_path,y_path)\n",
    "\n",
    "#Y_dict = {}\n",
    "#for row in Y:\n",
    "    #print(row[0],row)\n",
    "#    Y_dict[row[0]]= row\n",
    "\n",
    "#for i in Y_dict.keys():\n",
    "#    continue\n",
    "    #print(i,\":\",Y_dict[i])\n",
    "\n",
    "#x_inp =X[72:73]\n",
    "#print(x_inp)        \n",
    "#X,Y = TextProcess(x_inp,Y_dict,x_path)\n",
    "#print(X)\n",
    "#print(\"\\n\\n\\n\",Y)\n",
    "#print(len(X))\n",
    "#print(len(Y))\n",
    "#print(\"dtype: \",X[0].dtype)\n",
    "#print(type(X[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#gen = CustomBatchGenerator(X,Y,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
